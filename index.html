<!DOCTYPE html>
<html>

<article>
  <header>
	<h1>LEARNING DEEP AND WIDE CONTEXTUAL REPRESENTATIONS USING BERT FOR STATISTICAL PARAMETRIC SPEECH SYNTHESIS</h1>
  </header>
</article>

<p><b>Authors:</b> Ya-Jie Zhang, Zhen-Hua Ling </p>

<div><b>Abstract:</b> In this paper, we propose a method of learning deep and wide contextual representations for statistical parametric speech synthesis (SPSS) using BERT, a pre-trained language representation model. Traditional acoustic models in SPSS utilize phoneme sequences and prosody labels as text input, and can not make full use of the deep linguistic representations of current and surrounding sentences. Therefore, this paper designs two context encoders, i.e., a sentence-window context encoder and a paragraph-level context encoder, to integrate the deep contextual representations extracted from multiple sentences by BERT into the Tacotron framework via an extra attention module. The parameters of BERT are pre-trained and then fine-tuned together with other components in the model. Experimental results on the Blizzard Challenge 2019 datastet show that both context encoders can reduce the prediction errors of acoustic features. The sentence-window context encoder improves the subjective performance of the baseline Tacotron model significantly.

</div>

<h3>Demos of generated speech</h3></a>
    <div>
    The Blizzard Challenge 2019 dataset was adopted in our experiments. We use the Griffin-Lim algorithm to reconstruct waveforms. The following demos show the generated speech of Baseline model, SW models and PL model and nature speech in test set and the order is always nature speech, Baseline, SW(K=1,woPE), SW(K=1,wPE), PL.
    </div>

   	<div>1. <i>这个是个测试哦。</i> </div>

    <blockquote>
    <table>
    <tr>
    <td align=center width=300>nature speech</td><td align=center width=300>Baseline model</td><td align=center width=300>SW(K=1,woPE)</td> <td align=center width=300>SW(K=1,wPE)</td><td align=center width=300></td>
    </tr>
    <tr>
    <td rowspan=2><audio src="http://home.ustc.edu.cn/~zyj008/ICASSP2019/audio/style_transfer/non-parallel/ref/19.wav" controls=""></audio></td>
    <td rowspan=2><audio src="http://home.ustc.edu.cn/~zyj008/ICASSP2019/audio/style_transfer/non-parallel/baseline/19.wav" controls=""></audio></td>
	<td rowspan=2><audio src="http://home.ustc.edu.cn/~zyj008/ICASSP2019/audio/style_transfer/non-parallel/vae/19.wav" controls=""></audio></td>
	<td rowspan=2><audio src="http://home.ustc.edu.cn/~zyj008/ICASSP2019/audio/style_transfer/non-parallel/vae/19.wav" controls=""></audio></td>
	<td rowspan=2><audio src="http://home.ustc.edu.cn/~zyj008/ICASSP2019/audio/style_transfer/non-parallel/vae/19.wav" controls=""></audio></td>
    </tr>
    </table>	
    </blockquote>   



<head>
<meta charset="UTF-8">
<title>Speech Demo</title>
</head>

<body>


 	

	
  </p>    
  
 </body>
</html>